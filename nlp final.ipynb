{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd08ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anjan\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\anjan\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from deep_translator import GoogleTranslator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d96544f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gpt2_model():\n",
    "    \"\"\"\n",
    "    Load the GPT-2 model and tokenizer for language generation.\n",
    "    \"\"\"\n",
    "    print(\"Loading GPT-2 model (this might take a moment)...\")\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "    model.eval()\n",
    "    print(\"GPT-2 model loaded!\\n\")\n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954d0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_supported_languages():\n",
    "    \"\"\"\n",
    "    Displays the supported languages for translation.\n",
    "    \"\"\"\n",
    "    language_list = [\n",
    "        \"english\", \"tamil\", \"kannada\", \"hindi\", \"telugu\", \"french\",\n",
    "        \"german\", \"spanish\", \"italian\", \"russian\", \"japanese\", \"korean\", \"chinese\"\n",
    "    ]\n",
    "    print(\"üåê Supported Languages:\")\n",
    "    print(\", \".join(language_list))\n",
    "    return language_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d80da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(source_text, source_lang, target_lang):\n",
    "    \"\"\"\n",
    "    Translate source text to English if needed and return the translated text.\n",
    "    Also translate back to target language after generating the predicted text.\n",
    "    \"\"\"\n",
    "    if source_lang != \"english\":\n",
    "        text_in_english = GoogleTranslator(source=source_lang, target='english').translate(source_text)\n",
    "        print(f\"üîÅ Translated to English: {text_in_english}\")\n",
    "    else:\n",
    "        text_in_english = source_text\n",
    "    return text_in_english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5701036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_words(text_in_english, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Use GPT-2 to predict the next words based on the given text.\n",
    "    \"\"\"\n",
    "    input_ids = tokenizer.encode(text_in_english, return_tensors='pt')\n",
    "    output = model.generate(input_ids, max_length=input_ids.shape[1] + 5, do_sample=True)\n",
    "    predicted_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(f\"üß† Next word prediction: {predicted_text}\")\n",
    "    return predicted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f7c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_back_to_target_language(predicted_text, target_lang):\n",
    "    \"\"\"\n",
    "    Translate the GPT-2 predicted text back to the target language if it's not English.\n",
    "    \"\"\"\n",
    "    if target_lang != \"english\":\n",
    "        translated_output = GoogleTranslator(source='english', target=target_lang).translate(predicted_text)\n",
    "        print(f\"üåç Final Output in {target_lang.title()}: {translated_output}\")\n",
    "    else:\n",
    "        print(f\"üåç Final Output in English: {predicted_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99dd7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_languages(source_lang, target_lang, language_list):\n",
    "    \"\"\"\n",
    "    Validates whether the entered source and target languages are in the supported languages list.\n",
    "    \"\"\"\n",
    "    if source_lang not in language_list:\n",
    "        print(f\"‚ùó Invalid source language '{source_lang}', defaulting to English.\")\n",
    "        source_lang = \"english\"\n",
    "    if target_lang not in language_list:\n",
    "        print(f\"‚ùó Invalid target language '{target_lang}', defaulting to English.\")\n",
    "        target_lang = \"english\"\n",
    "    return source_lang, target_lang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08564d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load the model and tokenizer once\n",
    "    tokenizer, model = load_gpt2_model()\n",
    "\n",
    "    # Display the supported languages\n",
    "    language_list = display_supported_languages()\n",
    "\n",
    "    # Get user input\n",
    "    source_text = input(\"\\nüìù Enter a sentence: \")\n",
    "    source_lang = input(\"üî† Enter source language: \").strip().lower()\n",
    "    target_lang = input(\"üåç Enter target language: \").strip().lower()\n",
    "\n",
    "    # Validate the languages\n",
    "    source_lang, target_lang = validate_languages(source_lang, target_lang, language_list)\n",
    "\n",
    "    # Translate the source text to English if necessary\n",
    "    text_in_english = translate_text(source_text, source_lang, target_lang)\n",
    "\n",
    "    # Predict the next words using GPT-2\n",
    "    predicted_text = predict_next_words(text_in_english, tokenizer, model)\n",
    "\n",
    "    # Translate the predicted text back to the target language\n",
    "    translate_back_to_target_language(predicted_text, target_lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e757134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT-2 model (this might take a moment)...\n",
      "GPT-2 model loaded!\n",
      "\n",
      "üåê Supported Languages:\n",
      "english, tamil, kannada, hindi, telugu, french, german, spanish, italian, russian, japanese, korean, chinese\n",
      "\n",
      "üìù Enter a sentence: My name is Diya\n",
      "üî† Enter source language: English\n",
      "üåç Enter target language: Kannada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Next word prediction: My name is Diyaev, and I'm\n",
      "üåç Final Output in Kannada: ‡≤®‡≤®‡≥ç‡≤® ‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å ‡≤¶‡≤ø‡≤Ø‡≤æ‡≤µ‡≥ç, ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤®‡≤æ‡≤®‡≥Å\n"
     ]
    }
   ],
   "source": [
    "# Run the main function to execute the entire process\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6b8194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
